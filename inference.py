import torch
import numpy as np
import os
from transformers import AutoTokenizer
from pathlib import Path

# --- å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— ---
from model.config import PI0Config 
from model.modeling_pi0 import PI0Policy
from data.dataset import Pi0Dataset
from utils.normalization import Normalizer

# ================= ğŸ”§ æ¨ç†é…ç½®åŒºåŸŸ =================
# 1. æ¨¡å‹è·¯å¾„
TRAINED_MODEL_PATH = "/root/Users/wangbo/minipi0/outputs/test/checkpoint-900"

# 2. åŸºç¡€é…ç½®
TOKENIZER_PATH = "/root/Users/wangbo/lerobot/tokenizers/paligemma" 
# å¦‚æœæœ¬åœ°æ²¡æœ‰ï¼Œå¯ä»¥ç”¨ google å®˜æ–¹çš„: "google/paligemma-3b-pt-224"
if not os.path.exists(TOKENIZER_PATH):
    TOKENIZER_PATH = "google/paligemma-3b-pt-224"

DATASET_ROOT = "/root/Users/wangbo/my_converted_dataset"
STATS_PATH = "/root/Users/wangbo/my_converted_dataset/meta/stats.json"

# 3. ç¡¬ä»¶
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ===================================================

def main():
    print(f"ğŸš€ å¼€å§‹æ¨ç†è¯„ä¼°! è®¾å¤‡: {DEVICE}")

    # ---------------------------------------------------------
    # 1. åŠ è½½ç»Ÿè®¡æ•°æ® (å¿…é¡»åœ¨åŠ è½½æ¨¡å‹å‰è·å–çœŸå®ç»´åº¦)
    # ---------------------------------------------------------
    print(f"Loading stats from {STATS_PATH}...")
    # âš ï¸ å¿…é¡»ç”¨ device="cpu"ï¼Œæ–¹ä¾¿åç»­ numpy è½¬æ¢
    normalizer = Normalizer(STATS_PATH, device="cpu") 
    
    if 'action' in normalizer.stats:
        real_action_dim = normalizer.stats['action']['mean'].shape[0]
        real_state_dim = normalizer.stats['observation.state']['mean'].shape[0]
        print(f"ğŸ“ çœŸå®æ•°æ®ç»´åº¦: Action={real_action_dim}, State={real_state_dim}")
    else:
        raise ValueError("ç»Ÿè®¡æ–‡ä»¶ä¸­ç¼ºå°‘ 'action' å­—æ®µï¼")

    # ---------------------------------------------------------
    # 2. åŠ è½½æ¨¡å‹ä¸é…ç½®
    # ---------------------------------------------------------
    print(f"ğŸ§  Loading trained model from: {TRAINED_MODEL_PATH}")
    if not os.path.exists(TRAINED_MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹è·¯å¾„ {TRAINED_MODEL_PATH}")
        return

    # A. åŠ è½½ Config
    config = PI0Config.from_pretrained(TRAINED_MODEL_PATH)
    
    # ğŸ”§ã€å…³é”®ä¿®å¤ã€‘å¼ºåˆ¶ä¿®æ­£ Config é‡Œçš„ç»´åº¦è®¾ç½®
    # å› ä¸ºåº•åº§é»˜è®¤å¯èƒ½æ˜¯ 32 ç»´ï¼Œè€Œæ‚¨çš„æ•°æ®æ˜¯ 7 ç»´
    # å¦‚æœä¸ä¿®æ­£ï¼ŒåŠ è½½æƒé‡æ—¶ä¼šæŠ¥é”™ size mismatch
    if config.max_action_dim != real_action_dim:
        print(f"âš ï¸ å‘ç°ç»´åº¦ä¸åŒ¹é… (Config={config.max_action_dim} vs Stats={real_action_dim})")
        print(f"ğŸ”§ æ­£åœ¨å¼ºåˆ¶ä¿®æ­£ Config ä»¥åŒ¹é…æ‚¨çš„æ•°æ®...")
        config.max_action_dim = real_action_dim
        config.max_state_dim = real_state_dim

    # B. åŠ è½½æƒé‡
    # ignore_mismatched_sizes=True æ˜¯ä¸ºäº†é˜²æ­¢ä¸€äº›æ— å…³ç´§è¦çš„å¤´ä¿¡æ¯æŠ¥é”™
    policy = PI0Policy.from_pretrained(
        TRAINED_MODEL_PATH, 
        config=config,
        ignore_mismatched_sizes=True 
    )
    policy.to(DEVICE)
    policy.eval() 

    # C. åŠ è½½ Tokenizer
    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)

    # ---------------------------------------------------------
    # 3. å‡†å¤‡æµ‹è¯•æ ·æœ¬
    # ---------------------------------------------------------
    # ä½¿ç”¨ train split ç¡®ä¿ä¸€å®šèƒ½è¯»åˆ°æ•°æ® (å³ä½¿åªæœ‰ä¸€ä¸ª episode)
    dataset = Pi0Dataset(
        root_dir=DATASET_ROOT,
        tokenizer=tokenizer,
        normalizer=normalizer,
        split="train", 
        image_size=224,
        action_chunk_size=50
    )
    
    # éšæœºå–ä¸€ä¸ªæ ·æœ¬ (ä¾‹å¦‚ç¬¬ 50 å¸§)
    sample_idx = 0
    if len(dataset) > 50: sample_idx = 50
    
    print(f"ğŸ§ª æŠ½å–ç¬¬ {sample_idx} å¸§ä½œä¸ºæµ‹è¯•æ ·æœ¬...")
    sample = dataset[sample_idx]

    # å¢åŠ  Batch ç»´åº¦: [C, H, W] -> [1, C, H, W]
    batch = {}
    for k, v in sample.items():
        if isinstance(v, torch.Tensor):
            batch[k] = v.unsqueeze(0).to(DEVICE) 

    # ---------------------------------------------------------
    # 4. æ‰§è¡Œæ¨ç† (ç”Ÿæˆå®Œæ•´è½¨è¿¹)
    # ---------------------------------------------------------
    print("âš¡ æ¨¡å‹æ­£åœ¨é¢„æµ‹å®Œæ•´åŠ¨ä½œè½¨è¿¹ (Chunk)...")
    
    with torch.no_grad():
        # âŒ ä¸ä½¿ç”¨ select_action (å®ƒåªè¿”å›ç¬¬ 1 æ­¥)
        # âœ… ä½¿ç”¨ sample_actions (è¿”å›æœªæ¥ 50 æ­¥)
        
        # 1. é¢„å¤„ç†
        images, img_masks = policy._preprocess_images(batch)
        state = policy.prepare_state(batch)
        lang_tokens = batch["observation.language_instruction.input_ids"]
        lang_masks = batch["observation.language_instruction.attention_mask"]

        # 2. ç”Ÿæˆè½¨è¿¹ [Batch, Chunk, Dim]
        full_actions = policy.model.sample_actions(
            images, img_masks, lang_tokens, lang_masks, state
        )

        # 3. æˆªæ–­åˆ°æœ‰æ•ˆç»´åº¦ (é˜²æ­¢ padding å¹²æ‰°)
        pred_actions_normalized = full_actions[:, :, :real_action_dim]

    # ---------------------------------------------------------
    # 5. åå¤„ç†ä¸å±•ç¤º
    # ---------------------------------------------------------
    # æ¬å› CPU
    pred_actions_normalized = pred_actions_normalized.cpu()
    gt_actions_normalized = sample["action"].unsqueeze(0).cpu()

    # æ£€æŸ¥ç»´åº¦
    if pred_actions_normalized.shape[-1] != real_action_dim:
        print(f"âŒ ç»´åº¦ä¾ç„¶é”™è¯¯: {pred_actions_normalized.shape}")
        return

    # åå½’ä¸€åŒ–
    print("ğŸ”„ æ­£åœ¨åå½’ä¸€åŒ– (è¿˜åŸä¸ºçœŸå®ç‰©ç†æ•°å€¼)...")
    pred_actions_real = normalizer.denormalize(pred_actions_normalized, key="action")
    gt_actions_real = normalizer.denormalize(gt_actions_normalized, key="action")

    # æ‰“å°è¡¨æ ¼
    print("\n" + "="*65)
    print(f"ğŸ“Š åŠ¨ä½œè½¨è¿¹å¯¹æ¯” (Action Chunking, ç¬¬ 1 ä¸ªå…³èŠ‚)")
    print("="*65)
    
    pred_np = pred_actions_real[0].numpy() # [Chunk, Dim]
    gt_np = gt_actions_real[0].numpy()     # [Chunk, Dim]
    
    print(f"{'Step (æœªæ¥)':<12} | {'é¢„æµ‹å€¼ (Pred)':<15} | {'çœŸå®å€¼ (GT)':<15} | {'è¯¯å·® (Diff)':<15}")
    print("-" * 65)
    
    # æ‰“å°å‰ 10 æ­¥ï¼Œçœ‹çœ‹è¿è´¯æ€§
    for t in range(10): 
        val_pred = pred_np[t, 0] 
        val_gt = gt_np[t, 0]
        diff = abs(val_pred - val_gt)
        print(f"T + {t:<8} | {val_pred:<15.4f} | {val_gt:<15.4f} | {diff:<15.4f}")

    # è®¡ç®—æ•´ä½“ Chunk çš„è¯¯å·®
    mse = np.mean((pred_np - gt_np) ** 2)
    print("-" * 65)
    print(f"ğŸ“‰ æ•´ä¸ªè½¨è¿¹ (50æ­¥) çš„å‡æ–¹è¯¯å·® (MSE): {mse:.6f}")
    print("=" * 65)

    if mse < 0.1:
        print("âœ… æˆåŠŸï¼æ¨¡å‹ä¸ä»…é¢„æµ‹äº†å½“å‰åŠ¨ä½œï¼Œè¿˜è§„åˆ’äº†æœªæ¥è½¨è¿¹ã€‚")
    else:
        print("âš ï¸ è¯¯å·®è¾ƒå¤§ï¼Œå¯èƒ½æ¨¡å‹è¿˜æœªæ”¶æ•›ã€‚")

if __name__ == "__main__":
    main()